{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Задание 0` <br> Выбрать любую модель машинного обучения и зафиксировать любой тип валидации. Обучить базовую модель и зафиксировать базовое качество модели. В каждом следующем задании нужно будет обучить выбранную модель и оценивать ее качество на зафиксированной схеме валидации. После каждого задания, требуется сделать вывод о достигаемом качестве модели, по сравнению с качестом из предыдущего шага."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/mnt/f/data/kg/HW2/assignment_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid = train_test_split(data.drop([\"isFraud\"], axis=1), train_size=0.7, random_state=1)\n",
    "y_train, y_valid = train_test_split(data[\"isFraud\"], train_size=0.7, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"nthread\": 6,\n",
    "    \"seed\": 27\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = data.select_dtypes(exclude=\"object\").drop(\"isFraud\", axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:49:04] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.81297\tvalid-auc:0.78768\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 20 rounds.\n",
      "[10]\ttrain-auc:0.84450\tvalid-auc:0.82188\n",
      "[20]\ttrain-auc:0.87890\tvalid-auc:0.85383\n",
      "[30]\ttrain-auc:0.90896\tvalid-auc:0.88494\n",
      "[40]\ttrain-auc:0.93285\tvalid-auc:0.89729\n",
      "[50]\ttrain-auc:0.95129\tvalid-auc:0.90514\n",
      "[60]\ttrain-auc:0.96291\tvalid-auc:0.90886\n",
      "[70]\ttrain-auc:0.96957\tvalid-auc:0.91265\n",
      "[80]\ttrain-auc:0.97298\tvalid-auc:0.91491\n",
      "[90]\ttrain-auc:0.97556\tvalid-auc:0.91652\n",
      "[100]\ttrain-auc:0.97835\tvalid-auc:0.91765\n",
      "[110]\ttrain-auc:0.98061\tvalid-auc:0.91899\n",
      "[120]\ttrain-auc:0.98247\tvalid-auc:0.92032\n",
      "[130]\ttrain-auc:0.98386\tvalid-auc:0.92168\n",
      "[140]\ttrain-auc:0.98542\tvalid-auc:0.92228\n",
      "[150]\ttrain-auc:0.98749\tvalid-auc:0.92332\n",
      "[160]\ttrain-auc:0.98839\tvalid-auc:0.92430\n",
      "[170]\ttrain-auc:0.98930\tvalid-auc:0.92471\n",
      "[180]\ttrain-auc:0.99027\tvalid-auc:0.92470\n",
      "[190]\ttrain-auc:0.99166\tvalid-auc:0.92539\n",
      "[200]\ttrain-auc:0.99256\tvalid-auc:0.92539\n",
      "[210]\ttrain-auc:0.99343\tvalid-auc:0.92470\n",
      "[220]\ttrain-auc:0.99404\tvalid-auc:0.92524\n",
      "[230]\ttrain-auc:0.99461\tvalid-auc:0.92560\n",
      "[240]\ttrain-auc:0.99505\tvalid-auc:0.92591\n",
      "[250]\ttrain-auc:0.99596\tvalid-auc:0.92581\n",
      "[260]\ttrain-auc:0.99641\tvalid-auc:0.92648\n",
      "[270]\ttrain-auc:0.99674\tvalid-auc:0.92679\n",
      "[280]\ttrain-auc:0.99692\tvalid-auc:0.92694\n",
      "[290]\ttrain-auc:0.99720\tvalid-auc:0.92705\n",
      "[300]\ttrain-auc:0.99764\tvalid-auc:0.92649\n",
      "[310]\ttrain-auc:0.99777\tvalid-auc:0.92651\n",
      "Stopping. Best iteration:\n",
      "[290]\ttrain-auc:0.99720\tvalid-auc:0.92705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(x_train[numeric], y_train)\n",
    "dvalid = xgb.DMatrix(x_valid[numeric], y_valid)\n",
    "\n",
    "model = xgb.train(\n",
    "    dtrain=dtrain,\n",
    "    params=xgb_params,\n",
    "    num_boost_round=500,\n",
    "    evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Задание 1` <br> Признак TransactionDT - это смещение в секундах относительно базовой даты. Базовая дата - 2017-12-01, преобразовать признак TransactionDT в datetime, прибавив к базовой дате исходное значение признака. Из полученного признака выделить год, месяц, день недели, час, день.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATE_UNIX = time.mktime(datetime.date(2017, 12, 1).timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['NewTransactionDT'] = pd.to_datetime(data.TransactionDT + BASE_DATE_UNIX, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hour'] = data.NewTransactionDT.dt.hour\n",
    "data['day'] = data.NewTransactionDT.dt.day\n",
    "data['month'] = data.NewTransactionDT.dt.month\n",
    "data['year'] = data.NewTransactionDT.dt.year\n",
    "data['weekday'] = data.NewTransactionDT.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = numeric.tolist() + ['hour', 'day', 'month', 'year', 'weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:49:33] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.81297\tvalid-auc:0.78768\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 20 rounds.\n",
      "[10]\ttrain-auc:0.84588\tvalid-auc:0.81989\n",
      "[20]\ttrain-auc:0.87899\tvalid-auc:0.85321\n",
      "[30]\ttrain-auc:0.91059\tvalid-auc:0.88448\n",
      "[40]\ttrain-auc:0.93464\tvalid-auc:0.89513\n",
      "[50]\ttrain-auc:0.95365\tvalid-auc:0.90279\n",
      "[60]\ttrain-auc:0.96391\tvalid-auc:0.90741\n",
      "[70]\ttrain-auc:0.96942\tvalid-auc:0.91116\n",
      "[80]\ttrain-auc:0.97255\tvalid-auc:0.91461\n",
      "[90]\ttrain-auc:0.97543\tvalid-auc:0.91596\n",
      "[100]\ttrain-auc:0.97800\tvalid-auc:0.91713\n",
      "[110]\ttrain-auc:0.97965\tvalid-auc:0.91946\n",
      "[120]\ttrain-auc:0.98237\tvalid-auc:0.92105\n",
      "[130]\ttrain-auc:0.98367\tvalid-auc:0.92035\n",
      "[140]\ttrain-auc:0.98525\tvalid-auc:0.92047\n",
      "Stopping. Best iteration:\n",
      "[121]\ttrain-auc:0.98251\tvalid-auc:0.92115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid = train_test_split(data.drop([\"isFraud\"], axis=1), train_size=0.7, random_state=1)\n",
    "y_train, y_valid = train_test_split(data[\"isFraud\"], train_size=0.7, random_state=1)\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train[ex1], y_train)\n",
    "dvalid = xgb.DMatrix(x_valid[ex1], y_valid)\n",
    "\n",
    "model = xgb.train(\n",
    "    dtrain=dtrain,\n",
    "    params=xgb_params,\n",
    "    num_boost_round=500,\n",
    "    evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление данных признаков не дало прироста в качестве на валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Задание 2` <br>\n",
    "Сгруппировать данные по `card1` и посчитать среднюю сумму транзакции. Добавить в качестве признака в набор данных. Посчитать разницу между суммой транзакцией пользователя и средней суммой транзакции по данному типу `card1`. Построить отношение этих признаков. Повторить процедуру для всех `card`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_features = data.columns[data.columns.str.contains('card')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card1 has NaNs: False\n",
      "card2 has NaNs: True\n",
      "card3 has NaNs: True\n",
      "card4 has NaNs: True\n",
      "card5 has NaNs: True\n",
      "card6 has NaNs: True\n"
     ]
    }
   ],
   "source": [
    "for feat in card_features:\n",
    "    print(f'{feat} has NaNs: {data[feat].isna().any()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.card2 = data.card2.fillna(data.card2.median())\n",
    "data.card3 = data.card3.fillna(data.card3.median())\n",
    "data.card4 = data.card4.fillna('unknown')\n",
    "data.card5 = data.card5.fillna(data.card5.median())\n",
    "data.card6 = data.card6.fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_by_group(df: pd.DataFrame, by: str, col: str) -> pd.DataFrame:\n",
    "    mean_values = df.groupby(by).mean().reset_index()[[by, col]]\n",
    "    mean_values[col].fillna('mean', inplace=True)\n",
    "    mean_values.columns = [by, f'Mean{col}_{by}']\n",
    "    return mean_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in card_features:\n",
    "    data = data.merge(get_mean_by_group(data, feat, 'TransactionAmt'), how='left', on=feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_card_features = data.columns[data.columns.str.contains('card')].drop(card_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MeanTransactionAmt_card1', 'MeanTransactionAmt_card2',\n",
       "       'MeanTransactionAmt_card3', 'MeanTransactionAmt_card4',\n",
       "       'MeanTransactionAmt_card5', 'MeanTransactionAmt_card6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_card_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_ratio(df: pd.DataFrame, amt_col: str, mean_col: str) -> pd.Series:\n",
    "    return (data[amt_col] - data[mean_col]) / data[mean_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_feat in new_card_features:\n",
    "    prefix = new_feat.split('_')[-1]\n",
    "    data[f'{prefix}_mean_diff_ratio'] = get_mean_ratio(data, 'TransactionAmt', new_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['card1_mean_diff_ratio',\n",
       " 'card2_mean_diff_ratio',\n",
       " 'card3_mean_diff_ratio',\n",
       " 'card4_mean_diff_ratio',\n",
       " 'card5_mean_diff_ratio',\n",
       " 'card6_mean_diff_ratio']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[data.columns.str.contains('ratio')].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MeanTransactionAmt_card1', 'MeanTransactionAmt_card2',\n",
       "       'MeanTransactionAmt_card3', 'MeanTransactionAmt_card4',\n",
       "       'MeanTransactionAmt_card5', 'MeanTransactionAmt_card6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_card_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = numeric.tolist() + new_card_features.tolist() + data.columns[data.columns.str.contains('ratio')].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:49:57] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.81640\tvalid-auc:0.79119\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 20 rounds.\n",
      "[10]\ttrain-auc:0.84034\tvalid-auc:0.81723\n",
      "[20]\ttrain-auc:0.88073\tvalid-auc:0.86068\n",
      "[30]\ttrain-auc:0.92279\tvalid-auc:0.89444\n",
      "[40]\ttrain-auc:0.94634\tvalid-auc:0.90579\n",
      "[50]\ttrain-auc:0.95842\tvalid-auc:0.91122\n",
      "[60]\ttrain-auc:0.96600\tvalid-auc:0.91342\n",
      "[70]\ttrain-auc:0.97128\tvalid-auc:0.91711\n",
      "[80]\ttrain-auc:0.97604\tvalid-auc:0.92103\n",
      "[90]\ttrain-auc:0.97909\tvalid-auc:0.92353\n",
      "[100]\ttrain-auc:0.98239\tvalid-auc:0.92481\n",
      "[110]\ttrain-auc:0.98406\tvalid-auc:0.92578\n",
      "[120]\ttrain-auc:0.98578\tvalid-auc:0.92653\n",
      "[130]\ttrain-auc:0.98707\tvalid-auc:0.92692\n",
      "[140]\ttrain-auc:0.98914\tvalid-auc:0.92859\n",
      "[150]\ttrain-auc:0.99015\tvalid-auc:0.92962\n",
      "[160]\ttrain-auc:0.99104\tvalid-auc:0.92969\n",
      "Stopping. Best iteration:\n",
      "[148]\ttrain-auc:0.99004\tvalid-auc:0.92992\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid = train_test_split(data.drop([\"isFraud\"], axis=1), train_size=0.7, random_state=1)\n",
    "y_train, y_valid = train_test_split(data[\"isFraud\"], train_size=0.7, random_state=1)\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train[ex2], y_train)\n",
    "dvalid = xgb.DMatrix(x_valid[ex2], y_valid)\n",
    "\n",
    "model = xgb.train(\n",
    "    dtrain=dtrain,\n",
    "    params=xgb_params,\n",
    "    num_boost_round=500,\n",
    "    evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С данными признаками качество на валидации несколько повысилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Задание 3` <br>\n",
    "Преобразовать признаки card_1 - card_6 с помощью Frequency Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in card_features:\n",
    "    freq_encoder = data[feat].value_counts(normalize=True)\n",
    "    data[f'{feat}_freq_encoded'] = data[feat].map(freq_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3 = numeric.tolist() + data.columns[data.columns.str.contains('encoded')].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:50:15] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.81751\tvalid-auc:0.78861\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 20 rounds.\n",
      "[10]\ttrain-auc:0.84051\tvalid-auc:0.81965\n",
      "[20]\ttrain-auc:0.88128\tvalid-auc:0.85841\n",
      "[30]\ttrain-auc:0.92014\tvalid-auc:0.88793\n",
      "[40]\ttrain-auc:0.94305\tvalid-auc:0.90328\n",
      "[50]\ttrain-auc:0.95593\tvalid-auc:0.90726\n",
      "[60]\ttrain-auc:0.96416\tvalid-auc:0.91054\n",
      "[70]\ttrain-auc:0.96959\tvalid-auc:0.91352\n",
      "[80]\ttrain-auc:0.97387\tvalid-auc:0.91662\n",
      "[90]\ttrain-auc:0.97674\tvalid-auc:0.91867\n",
      "[100]\ttrain-auc:0.97952\tvalid-auc:0.91995\n",
      "[110]\ttrain-auc:0.98196\tvalid-auc:0.92173\n",
      "[120]\ttrain-auc:0.98363\tvalid-auc:0.92300\n",
      "[130]\ttrain-auc:0.98522\tvalid-auc:0.92218\n",
      "[140]\ttrain-auc:0.98668\tvalid-auc:0.92296\n",
      "Stopping. Best iteration:\n",
      "[120]\ttrain-auc:0.98363\tvalid-auc:0.92300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid = train_test_split(data.drop([\"isFraud\"], axis=1), train_size=0.7, random_state=1)\n",
    "y_train, y_valid = train_test_split(data[\"isFraud\"], train_size=0.7, random_state=1)\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train[ex3], y_train)\n",
    "dvalid = xgb.DMatrix(x_valid[ex3], y_valid)\n",
    "\n",
    "model = xgb.train(\n",
    "    dtrain=dtrain,\n",
    "    params=xgb_params,\n",
    "    num_boost_round=500,\n",
    "    evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные признаки не дали прироста в качестве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Задание 4` <br>\n",
    "Преобразовать признак TransactionAmt в логарифм признака, выделить дробную часть и целую часть в отдельные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LogTransactionAmt'] = np.log(data.TransactionAmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LogFractionalTransactionAmt'], data['LogIntegralTransactionAmt']  = np.modf(data.LogTransactionAmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex4 = numeric.tolist() + ['LogTransactionAmt', 'LogFractionalTransactionAmt', 'LogIntegralTransactionAmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:54:55] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.81297\tvalid-auc:0.78768\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 20 rounds.\n",
      "[10]\ttrain-auc:0.84410\tvalid-auc:0.82207\n",
      "[20]\ttrain-auc:0.87620\tvalid-auc:0.85379\n",
      "[30]\ttrain-auc:0.91136\tvalid-auc:0.88692\n",
      "[40]\ttrain-auc:0.93490\tvalid-auc:0.89732\n",
      "[50]\ttrain-auc:0.95281\tvalid-auc:0.90526\n",
      "[60]\ttrain-auc:0.96000\tvalid-auc:0.90850\n",
      "[70]\ttrain-auc:0.96682\tvalid-auc:0.91288\n",
      "[80]\ttrain-auc:0.97055\tvalid-auc:0.91527\n",
      "[90]\ttrain-auc:0.97440\tvalid-auc:0.91706\n",
      "[100]\ttrain-auc:0.97757\tvalid-auc:0.91806\n",
      "[110]\ttrain-auc:0.97933\tvalid-auc:0.91993\n",
      "[120]\ttrain-auc:0.98132\tvalid-auc:0.92070\n",
      "[130]\ttrain-auc:0.98309\tvalid-auc:0.92087\n",
      "[140]\ttrain-auc:0.98501\tvalid-auc:0.92253\n",
      "[150]\ttrain-auc:0.98610\tvalid-auc:0.92290\n",
      "[160]\ttrain-auc:0.98770\tvalid-auc:0.92407\n",
      "[170]\ttrain-auc:0.98882\tvalid-auc:0.92474\n",
      "[180]\ttrain-auc:0.98980\tvalid-auc:0.92523\n",
      "[190]\ttrain-auc:0.99059\tvalid-auc:0.92517\n",
      "[200]\ttrain-auc:0.99132\tvalid-auc:0.92575\n",
      "[210]\ttrain-auc:0.99211\tvalid-auc:0.92586\n",
      "[220]\ttrain-auc:0.99281\tvalid-auc:0.92557\n",
      "[230]\ttrain-auc:0.99339\tvalid-auc:0.92578\n",
      "Stopping. Best iteration:\n",
      "[215]\ttrain-auc:0.99263\tvalid-auc:0.92616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid = train_test_split(data.drop([\"isFraud\"], axis=1), train_size=0.7, random_state=1)\n",
    "y_train, y_valid = train_test_split(data[\"isFraud\"], train_size=0.7, random_state=1)\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train[ex4], y_train)\n",
    "dvalid = xgb.DMatrix(x_valid[ex4], y_valid)\n",
    "\n",
    "model = xgb.train(\n",
    "    dtrain=dtrain,\n",
    "    params=xgb_params,\n",
    "    num_boost_round=500,\n",
    "    evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные признаки не дали прироста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Задание 5` <br>\n",
    "Для числовых признаков построить PCA-признаки, добавить их к основной части датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data_rescaled = np.nan_to_num(scaler.fit_transform(data[numeric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.95)\n",
    "pca.fit(numeric_data_rescaled)\n",
    "reduced = pca.transform(numeric_data_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50001, 37)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cols = [f'pca_comp_{i + 1}' for i in range(reduced.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_feats = pd.DataFrame(reduced, columns=pca_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_comp_1</th>\n",
       "      <th>pca_comp_2</th>\n",
       "      <th>pca_comp_3</th>\n",
       "      <th>pca_comp_4</th>\n",
       "      <th>pca_comp_5</th>\n",
       "      <th>pca_comp_6</th>\n",
       "      <th>pca_comp_7</th>\n",
       "      <th>pca_comp_8</th>\n",
       "      <th>pca_comp_9</th>\n",
       "      <th>pca_comp_10</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_comp_28</th>\n",
       "      <th>pca_comp_29</th>\n",
       "      <th>pca_comp_30</th>\n",
       "      <th>pca_comp_31</th>\n",
       "      <th>pca_comp_32</th>\n",
       "      <th>pca_comp_33</th>\n",
       "      <th>pca_comp_34</th>\n",
       "      <th>pca_comp_35</th>\n",
       "      <th>pca_comp_36</th>\n",
       "      <th>pca_comp_37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.448290</td>\n",
       "      <td>0.118089</td>\n",
       "      <td>-0.829621</td>\n",
       "      <td>0.123170</td>\n",
       "      <td>-0.870317</td>\n",
       "      <td>0.316176</td>\n",
       "      <td>-0.159314</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.354754</td>\n",
       "      <td>-0.210481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>-0.016541</td>\n",
       "      <td>-0.034675</td>\n",
       "      <td>-0.044837</td>\n",
       "      <td>0.047133</td>\n",
       "      <td>-0.030688</td>\n",
       "      <td>0.031893</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>-0.139471</td>\n",
       "      <td>-0.015347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.429116</td>\n",
       "      <td>-0.477001</td>\n",
       "      <td>0.117416</td>\n",
       "      <td>-0.484874</td>\n",
       "      <td>-0.467635</td>\n",
       "      <td>-0.311322</td>\n",
       "      <td>0.347840</td>\n",
       "      <td>-0.004052</td>\n",
       "      <td>0.253741</td>\n",
       "      <td>-0.248502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015045</td>\n",
       "      <td>0.036552</td>\n",
       "      <td>0.009151</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>-0.010747</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>-0.064831</td>\n",
       "      <td>0.010892</td>\n",
       "      <td>0.055379</td>\n",
       "      <td>0.069832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.001694</td>\n",
       "      <td>0.454697</td>\n",
       "      <td>-0.302933</td>\n",
       "      <td>0.084389</td>\n",
       "      <td>-0.655174</td>\n",
       "      <td>0.121912</td>\n",
       "      <td>0.559673</td>\n",
       "      <td>-0.301947</td>\n",
       "      <td>0.021730</td>\n",
       "      <td>-0.185675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133241</td>\n",
       "      <td>-0.023098</td>\n",
       "      <td>-0.020894</td>\n",
       "      <td>0.009359</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>-0.004293</td>\n",
       "      <td>0.028928</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>-0.108385</td>\n",
       "      <td>-0.006223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.652390</td>\n",
       "      <td>-0.248912</td>\n",
       "      <td>0.033116</td>\n",
       "      <td>-0.525432</td>\n",
       "      <td>-0.270255</td>\n",
       "      <td>-0.488559</td>\n",
       "      <td>0.348090</td>\n",
       "      <td>-0.260415</td>\n",
       "      <td>0.841362</td>\n",
       "      <td>-0.150946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112022</td>\n",
       "      <td>0.611581</td>\n",
       "      <td>-0.000345</td>\n",
       "      <td>-0.300995</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>0.125365</td>\n",
       "      <td>-0.277122</td>\n",
       "      <td>0.114593</td>\n",
       "      <td>-0.142233</td>\n",
       "      <td>-0.053720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.978311</td>\n",
       "      <td>0.336832</td>\n",
       "      <td>-0.110268</td>\n",
       "      <td>-0.437020</td>\n",
       "      <td>-0.491395</td>\n",
       "      <td>0.153819</td>\n",
       "      <td>0.457403</td>\n",
       "      <td>-0.116508</td>\n",
       "      <td>0.394048</td>\n",
       "      <td>-0.157278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009947</td>\n",
       "      <td>0.021506</td>\n",
       "      <td>0.046290</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.014767</td>\n",
       "      <td>-0.042830</td>\n",
       "      <td>0.170834</td>\n",
       "      <td>0.074464</td>\n",
       "      <td>0.172753</td>\n",
       "      <td>-0.269234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>1.286510</td>\n",
       "      <td>-0.372167</td>\n",
       "      <td>-0.180067</td>\n",
       "      <td>0.908053</td>\n",
       "      <td>0.633950</td>\n",
       "      <td>-0.234030</td>\n",
       "      <td>-0.104473</td>\n",
       "      <td>-0.186752</td>\n",
       "      <td>0.153131</td>\n",
       "      <td>0.142003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>-0.005277</td>\n",
       "      <td>-0.041161</td>\n",
       "      <td>0.010978</td>\n",
       "      <td>0.026186</td>\n",
       "      <td>-0.012555</td>\n",
       "      <td>-0.009895</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>-0.018431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>-0.505236</td>\n",
       "      <td>-0.086761</td>\n",
       "      <td>0.453614</td>\n",
       "      <td>0.012628</td>\n",
       "      <td>0.386921</td>\n",
       "      <td>-0.556890</td>\n",
       "      <td>-0.355223</td>\n",
       "      <td>0.395926</td>\n",
       "      <td>-0.325108</td>\n",
       "      <td>0.078819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.017897</td>\n",
       "      <td>-0.010823</td>\n",
       "      <td>-0.021716</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>-0.015317</td>\n",
       "      <td>0.094297</td>\n",
       "      <td>0.068122</td>\n",
       "      <td>-0.065191</td>\n",
       "      <td>-0.037271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>-0.334439</td>\n",
       "      <td>-0.752569</td>\n",
       "      <td>1.698128</td>\n",
       "      <td>0.448838</td>\n",
       "      <td>-0.217243</td>\n",
       "      <td>0.273553</td>\n",
       "      <td>-0.413614</td>\n",
       "      <td>-0.312511</td>\n",
       "      <td>0.168259</td>\n",
       "      <td>-0.584717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099804</td>\n",
       "      <td>-0.389674</td>\n",
       "      <td>-0.119595</td>\n",
       "      <td>0.341733</td>\n",
       "      <td>-0.079213</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>0.024260</td>\n",
       "      <td>0.049768</td>\n",
       "      <td>0.127286</td>\n",
       "      <td>-0.151687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1.277914</td>\n",
       "      <td>-0.460006</td>\n",
       "      <td>-0.124791</td>\n",
       "      <td>0.945504</td>\n",
       "      <td>0.426738</td>\n",
       "      <td>-0.148474</td>\n",
       "      <td>-0.136491</td>\n",
       "      <td>0.363417</td>\n",
       "      <td>0.203290</td>\n",
       "      <td>0.078346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004364</td>\n",
       "      <td>-0.010176</td>\n",
       "      <td>-0.005409</td>\n",
       "      <td>0.012395</td>\n",
       "      <td>0.033515</td>\n",
       "      <td>-0.013624</td>\n",
       "      <td>-0.017233</td>\n",
       "      <td>-0.004300</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>-0.031161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>-0.497459</td>\n",
       "      <td>-0.075686</td>\n",
       "      <td>0.464923</td>\n",
       "      <td>0.018053</td>\n",
       "      <td>0.422388</td>\n",
       "      <td>-0.543650</td>\n",
       "      <td>-0.361131</td>\n",
       "      <td>0.105072</td>\n",
       "      <td>-0.151071</td>\n",
       "      <td>0.227626</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.015646</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>-0.021455</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>-0.020280</td>\n",
       "      <td>0.096677</td>\n",
       "      <td>0.066482</td>\n",
       "      <td>-0.065689</td>\n",
       "      <td>-0.033646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50001 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pca_comp_1  pca_comp_2  pca_comp_3  pca_comp_4  pca_comp_5  pca_comp_6  \\\n",
       "0       -0.448290    0.118089   -0.829621    0.123170   -0.870317    0.316176   \n",
       "1       -0.429116   -0.477001    0.117416   -0.484874   -0.467635   -0.311322   \n",
       "2       -1.001694    0.454697   -0.302933    0.084389   -0.655174    0.121912   \n",
       "3       -0.652390   -0.248912    0.033116   -0.525432   -0.270255   -0.488559   \n",
       "4        1.978311    0.336832   -0.110268   -0.437020   -0.491395    0.153819   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "49996    1.286510   -0.372167   -0.180067    0.908053    0.633950   -0.234030   \n",
       "49997   -0.505236   -0.086761    0.453614    0.012628    0.386921   -0.556890   \n",
       "49998   -0.334439   -0.752569    1.698128    0.448838   -0.217243    0.273553   \n",
       "49999    1.277914   -0.460006   -0.124791    0.945504    0.426738   -0.148474   \n",
       "50000   -0.497459   -0.075686    0.464923    0.018053    0.422388   -0.543650   \n",
       "\n",
       "       pca_comp_7  pca_comp_8  pca_comp_9  pca_comp_10  ...  pca_comp_28  \\\n",
       "0       -0.159314    0.003322    0.354754    -0.210481  ...     0.000266   \n",
       "1        0.347840   -0.004052    0.253741    -0.248502  ...     0.015045   \n",
       "2        0.559673   -0.301947    0.021730    -0.185675  ...    -0.133241   \n",
       "3        0.348090   -0.260415    0.841362    -0.150946  ...     0.112022   \n",
       "4        0.457403   -0.116508    0.394048    -0.157278  ...    -0.009947   \n",
       "...           ...         ...         ...          ...  ...          ...   \n",
       "49996   -0.104473   -0.186752    0.153131     0.142003  ...     0.008245   \n",
       "49997   -0.355223    0.395926   -0.325108     0.078819  ...     0.001752   \n",
       "49998   -0.413614   -0.312511    0.168259    -0.584717  ...     0.099804   \n",
       "49999   -0.136491    0.363417    0.203290     0.078346  ...    -0.004364   \n",
       "50000   -0.361131    0.105072   -0.151071     0.227626  ...    -0.000013   \n",
       "\n",
       "       pca_comp_29  pca_comp_30  pca_comp_31  pca_comp_32  pca_comp_33  \\\n",
       "0        -0.016541    -0.034675    -0.044837     0.047133    -0.030688   \n",
       "1         0.036552     0.009151    -0.000748    -0.010747     0.002280   \n",
       "2        -0.023098    -0.020894     0.009359     0.005069    -0.004293   \n",
       "3         0.611581    -0.000345    -0.300995     0.183946     0.125365   \n",
       "4         0.021506     0.046290     0.005213     0.014767    -0.042830   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "49996    -0.005277    -0.041161     0.010978     0.026186    -0.012555   \n",
       "49997     0.017897    -0.010823    -0.021716     0.005462    -0.015317   \n",
       "49998    -0.389674    -0.119595     0.341733    -0.079213     0.028512   \n",
       "49999    -0.010176    -0.005409     0.012395     0.033515    -0.013624   \n",
       "50000     0.015646     0.000547    -0.021455     0.007665    -0.020280   \n",
       "\n",
       "       pca_comp_34  pca_comp_35  pca_comp_36  pca_comp_37  \n",
       "0         0.031893     0.003632    -0.139471    -0.015347  \n",
       "1        -0.064831     0.010892     0.055379     0.069832  \n",
       "2         0.028928     0.037079    -0.108385    -0.006223  \n",
       "3        -0.277122     0.114593    -0.142233    -0.053720  \n",
       "4         0.170834     0.074464     0.172753    -0.269234  \n",
       "...            ...          ...          ...          ...  \n",
       "49996    -0.009895     0.004034     0.001625    -0.018431  \n",
       "49997     0.094297     0.068122    -0.065191    -0.037271  \n",
       "49998     0.024260     0.049768     0.127286    -0.151687  \n",
       "49999    -0.017233    -0.004300     0.000965    -0.031161  \n",
       "50000     0.096677     0.066482    -0.065689    -0.033646  \n",
       "\n",
       "[50001 rows x 37 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, pca_feats], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex5 = numeric.tolist() + pca_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:05:48] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.81298\tvalid-auc:0.78763\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 20 rounds.\n",
      "[10]\ttrain-auc:0.83991\tvalid-auc:0.82205\n",
      "[20]\ttrain-auc:0.87701\tvalid-auc:0.85791\n",
      "[30]\ttrain-auc:0.92089\tvalid-auc:0.88487\n",
      "[40]\ttrain-auc:0.94561\tvalid-auc:0.89301\n",
      "[50]\ttrain-auc:0.96105\tvalid-auc:0.89986\n",
      "[60]\ttrain-auc:0.96935\tvalid-auc:0.90561\n",
      "[70]\ttrain-auc:0.97450\tvalid-auc:0.90895\n",
      "[80]\ttrain-auc:0.97784\tvalid-auc:0.90975\n",
      "[90]\ttrain-auc:0.98156\tvalid-auc:0.91057\n",
      "[100]\ttrain-auc:0.98464\tvalid-auc:0.91116\n",
      "[110]\ttrain-auc:0.98750\tvalid-auc:0.91155\n",
      "[120]\ttrain-auc:0.99089\tvalid-auc:0.91270\n",
      "[130]\ttrain-auc:0.99226\tvalid-auc:0.91340\n",
      "[140]\ttrain-auc:0.99344\tvalid-auc:0.91346\n",
      "[150]\ttrain-auc:0.99513\tvalid-auc:0.91289\n",
      "Stopping. Best iteration:\n",
      "[135]\ttrain-auc:0.99282\tvalid-auc:0.91390\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid = train_test_split(data.drop([\"isFraud\"], axis=1), train_size=0.7, random_state=1)\n",
    "y_train, y_valid = train_test_split(data[\"isFraud\"], train_size=0.7, random_state=1)\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train[ex5], y_train)\n",
    "dvalid = xgb.DMatrix(x_valid[ex5], y_valid)\n",
    "\n",
    "model = xgb.train(\n",
    "    dtrain=dtrain,\n",
    "    params=xgb_params,\n",
    "    num_boost_round=500,\n",
    "    evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Задание 6` \n",
    "Использовать критерий отбора признаков на основе перестановок для отбора признаков, которые положительно влияют на перформанс модели. Переобучить модель и сделать выводы о полученном качестве алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex6 = list(set(ex1 + ex2 + ex3 + ex4 + ex5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:09:41] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.82004\tvalid-auc:0.79440\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 20 rounds.\n",
      "[10]\ttrain-auc:0.84685\tvalid-auc:0.82620\n",
      "[20]\ttrain-auc:0.88532\tvalid-auc:0.86371\n",
      "[30]\ttrain-auc:0.93008\tvalid-auc:0.89136\n",
      "[40]\ttrain-auc:0.95374\tvalid-auc:0.90062\n",
      "[50]\ttrain-auc:0.96983\tvalid-auc:0.90848\n",
      "[60]\ttrain-auc:0.97683\tvalid-auc:0.91234\n",
      "[70]\ttrain-auc:0.98212\tvalid-auc:0.91541\n",
      "[80]\ttrain-auc:0.98508\tvalid-auc:0.91719\n",
      "[90]\ttrain-auc:0.98779\tvalid-auc:0.91967\n",
      "[100]\ttrain-auc:0.98974\tvalid-auc:0.92133\n",
      "[110]\ttrain-auc:0.99182\tvalid-auc:0.92289\n",
      "[120]\ttrain-auc:0.99333\tvalid-auc:0.92277\n",
      "[130]\ttrain-auc:0.99445\tvalid-auc:0.92310\n",
      "Stopping. Best iteration:\n",
      "[112]\ttrain-auc:0.99241\tvalid-auc:0.92326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid = train_test_split(data.drop([\"isFraud\"], axis=1), train_size=0.7, random_state=1)\n",
    "y_train, y_valid = train_test_split(data[\"isFraud\"], train_size=0.7, random_state=1)\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train[ex6], y_train)\n",
    "dvalid = xgb.DMatrix(x_valid[ex6], y_valid)\n",
    "\n",
    "model = xgb.train(\n",
    "    dtrain=dtrain,\n",
    "    params=xgb_params,\n",
    "    num_boost_round=500,\n",
    "    evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(params=xgb_params,\n",
    "                     num_boost_round=500,\n",
    "                     early_stopping_rounds=20,\n",
    "                     verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:18:13] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { early_stopping_rounds, num_boost_round, params, verbose_eval } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, early_stopping_rounds=20,\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "              num_boost_round=500, num_parallel_tree=1,\n",
       "              params={'booster': 'gbtree', 'eval_metric': 'auc',\n",
       "                      'learning_rate': 0.1, 'n_estimators': 1000, 'nthread': 6,\n",
       "                      'objective': 'binary:logistic', 'seed': 27},\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbose_eval=10, verbosity=None)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc.fit(x_train[ex6], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.48 s, sys: 1.55 s, total: 6.03 s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feature_importances = permutation_importance(xgbc, x_valid[ex6], y_valid, n_jobs=4, n_repeats=3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`The permutation importance is defined to be the difference between the baseline metric and metric from permutating the feature column.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_indices = np.where(feature_importances.importances_mean < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.88856298e-04, -3.33311113e-04, -2.88869631e-04, -1.99986668e-04,\n",
       "       -1.55545186e-04, -1.33324445e-04, -1.33324445e-04, -1.33324445e-04,\n",
       "       -1.33324445e-04, -1.11103704e-04, -1.11103704e-04, -1.11103704e-04,\n",
       "       -1.11103704e-04, -1.11103704e-04, -1.11103704e-04, -8.88829634e-05,\n",
       "       -8.88829634e-05, -8.88829634e-05, -6.66622225e-05, -6.66622225e-05,\n",
       "       -6.66622225e-05, -6.66622225e-05, -6.66622225e-05, -6.66622225e-05,\n",
       "       -6.66622225e-05, -6.66622225e-05, -4.44414817e-05, -4.44414817e-05,\n",
       "       -4.44414817e-05, -4.44414817e-05, -4.44414817e-05, -4.44414817e-05,\n",
       "       -4.44414817e-05, -4.44414817e-05, -4.44414817e-05, -4.44414817e-05,\n",
       "       -4.44414817e-05, -4.44414817e-05, -2.22207408e-05, -2.22207408e-05,\n",
       "       -2.22207408e-05, -2.22207408e-05, -2.22207408e-05, -2.22207408e-05,\n",
       "       -2.22207408e-05, -2.22207408e-05, -2.22207408e-05])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.importances_mean[importance_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(22, 12))\n",
    "g = sns.barplot(x=feature_importances.importances_mean[importance_indices], y=data[ex6].columns[importance_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:54:49] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.74831\tvalid-auc:0.71558\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 20 rounds.\n",
      "[10]\ttrain-auc:0.83269\tvalid-auc:0.80691\n",
      "[20]\ttrain-auc:0.85881\tvalid-auc:0.83068\n",
      "[30]\ttrain-auc:0.88004\tvalid-auc:0.84044\n",
      "[40]\ttrain-auc:0.89211\tvalid-auc:0.84752\n",
      "[50]\ttrain-auc:0.90711\tvalid-auc:0.85133\n",
      "[60]\ttrain-auc:0.91576\tvalid-auc:0.85533\n",
      "[70]\ttrain-auc:0.92404\tvalid-auc:0.85813\n",
      "[80]\ttrain-auc:0.93018\tvalid-auc:0.85991\n",
      "[90]\ttrain-auc:0.93397\tvalid-auc:0.86054\n",
      "[100]\ttrain-auc:0.93785\tvalid-auc:0.86338\n",
      "[110]\ttrain-auc:0.94120\tvalid-auc:0.86421\n",
      "[120]\ttrain-auc:0.94516\tvalid-auc:0.86405\n",
      "[130]\ttrain-auc:0.94796\tvalid-auc:0.86417\n",
      "Stopping. Best iteration:\n",
      "[114]\ttrain-auc:0.94210\tvalid-auc:0.86474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid = train_test_split(data.drop([\"isFraud\"], axis=1), train_size=0.7, random_state=1)\n",
    "y_train, y_valid = train_test_split(data[\"isFraud\"], train_size=0.7, random_state=1)\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train[data[ex6].columns[importance_indices]], y_train)\n",
    "dvalid = xgb.DMatrix(x_valid[data[ex6].columns[importance_indices]], y_valid)\n",
    "\n",
    "model = xgb.train(\n",
    "    dtrain=dtrain,\n",
    "    params=xgb_params,\n",
    "    num_boost_round=500,\n",
    "    evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_indices = np.where(feature_importances.importances_mean <= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:57:20] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.75508\tvalid-auc:0.73773\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 20 rounds.\n",
      "[10]\ttrain-auc:0.84637\tvalid-auc:0.82073\n",
      "[20]\ttrain-auc:0.87961\tvalid-auc:0.86028\n",
      "[30]\ttrain-auc:0.92737\tvalid-auc:0.88258\n",
      "[40]\ttrain-auc:0.95336\tvalid-auc:0.89771\n",
      "[50]\ttrain-auc:0.96827\tvalid-auc:0.90662\n",
      "[60]\ttrain-auc:0.97654\tvalid-auc:0.91218\n",
      "[70]\ttrain-auc:0.98055\tvalid-auc:0.91417\n",
      "[80]\ttrain-auc:0.98381\tvalid-auc:0.91652\n",
      "[90]\ttrain-auc:0.98637\tvalid-auc:0.91720\n",
      "[100]\ttrain-auc:0.98835\tvalid-auc:0.91811\n",
      "[110]\ttrain-auc:0.99037\tvalid-auc:0.91953\n",
      "[120]\ttrain-auc:0.99243\tvalid-auc:0.92059\n",
      "[130]\ttrain-auc:0.99430\tvalid-auc:0.91983\n",
      "[140]\ttrain-auc:0.99512\tvalid-auc:0.92029\n",
      "Stopping. Best iteration:\n",
      "[120]\ttrain-auc:0.99243\tvalid-auc:0.92059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid = train_test_split(data.drop([\"isFraud\"], axis=1), train_size=0.7, random_state=1)\n",
    "y_train, y_valid = train_test_split(data[\"isFraud\"], train_size=0.7, random_state=1)\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train[data[ex6].columns[importance_indices]], y_train)\n",
    "dvalid = xgb.DMatrix(x_valid[data[ex6].columns[importance_indices]], y_valid)\n",
    "\n",
    "model = xgb.train(\n",
    "    dtrain=dtrain,\n",
    "    params=xgb_params,\n",
    "    num_boost_round=500,\n",
    "    evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, что на данном датасете это не особо помогло, но во всяком случае урезание ~ 100 фичей практически не снижает качество на валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
